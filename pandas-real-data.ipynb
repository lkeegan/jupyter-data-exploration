{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e4bbd6c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Exploration with Python and Jupyter\n",
    "\n",
    "Basic usage of the Pandas library to download a dataset,\n",
    "explore its contents, clean up missing or invalid data,\n",
    "filter the data according to different criteria,\n",
    "and plot visualizations of the data.\n",
    "\n",
    "- [Part 1: Python and Jupyter](https://ssciwr.github.io/jupyter-data-exploration)\n",
    "- [Part 2: Pandas with toy data](https://ssciwr.github.io/jupyter-data-exploration/pandas-toy-data.slides.html)\n",
    "- **Part 3: Pandas with real data**\n",
    "\n",
    "*Press `Spacebar` to go to the next slide (or `?` to see all navigation shortcuts)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1480d7d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's download some real data\n",
    "\n",
    "For some reason, the London Fire Brigade provides a public spreadsheet of all animal rescue incidents since 2009:\n",
    "\n",
    "https://data.london.gov.uk/dataset/animal-rescue-incidents-attended-by-lfb\n",
    "\n",
    "They provide a link to the dataset in csv (comma-delimited) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16c9318",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# import the Pandas library & matplotlib for plotting\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189a6a56",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# download a csv file with some data and convert it to a DataFrame\n",
    "url = \"https://data.london.gov.uk/download/animal-rescue-incidents-attended-by-lfb/8a7d91c2-9aec-4bde-937a-3998f4717cd8/Animal%20Rescue%20incidents%20attended%20by%20LFB%20from%20Jan%202009.csv\"\n",
    "df = pd.read_csv(url, encoding=\"unicode_escape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea21e7b6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Sidenote\n",
    "\n",
    "You may be wondering what this `encoding='unicode_escape'` parameter is for, and how did I know it needed to be there?\n",
    "\n",
    "Well, I first tried `pd.read_csv(url)` and got this:\n",
    "\n",
    "```\n",
    "---------------------------------------------------------------------------\n",
    "UnicodeDecodeError                        Traceback (most recent call last)\n",
    "/tmp/ipykernel_514329/874975015.py in <module>\n",
    "----> 1 pd.read_csv(url)\n",
    "\n",
    "~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/pandas/io/parsers.py in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\n",
    "    608     kwds.update(kwds_defaults)\n",
    "    609 \n",
    "--> 610     return _read(filepath_or_buffer, kwds)\n",
    "    611 \n",
    "    612 \n",
    "\n",
    "~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/pandas/io/parsers.py in _read(filepath_or_buffer, kwds)\n",
    "    460 \n",
    "    461     # Create the parser.\n",
    "--> 462     parser = TextFileReader(filepath_or_buffer, **kwds)\n",
    "    463 \n",
    "    464     if chunksize or iterator:\n",
    "\n",
    "~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/pandas/io/parsers.py in __init__(self, f, engine, **kwds)\n",
    "    817             self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n",
    "    818 \n",
    "--> 819         self._engine = self._make_engine(self.engine)\n",
    "    820 \n",
    "    821     def close(self):\n",
    "\n",
    "~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/pandas/io/parsers.py in _make_engine(self, engine)\n",
    "   1048             )\n",
    "   1049         # error: Too many arguments for \"ParserBase\"\n",
    "-> 1050         return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n",
    "   1051 \n",
    "   1052     def _failover_to_python(self):\n",
    "\n",
    "~/.pyenv/versions/3.9.4/lib/python3.9/site-packages/pandas/io/parsers.py in __init__(self, src, **kwds)\n",
    "   1896 \n",
    "   1897         try:\n",
    "-> 1898             self._reader = parsers.TextReader(self.handles.handle, **kwds)\n",
    "   1899         except Exception:\n",
    "   1900             self.handles.close()\n",
    "\n",
    "pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader.__cinit__()\n",
    "\n",
    "pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._get_header()\n",
    "\n",
    "pandas/_libs/parsers.pyx in pandas._libs.parsers.TextReader._tokenize_rows()\n",
    "\n",
    "pandas/_libs/parsers.pyx in pandas._libs.parsers.raise_parser_error()\n",
    "\n",
    "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa3 in position 105: invalid start byte\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8ff4f2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Suggested workflow / philosophy\n",
    "\n",
    "- you want to do something\n",
    "  - if you know / have a guess which function to use, look at its docstring: `?function_name`\n",
    "  - if you don't have any idea what to try, google `how do I ... in pandas`\n",
    "  - if in doubt, just try something!\n",
    "- if you get an error, copy & paste the last bit into google (along with `funtion_name` and/or `pandas`)\n",
    "  - don't be intimidated by the long and apparently nonsensical error messages\n",
    "  - almost certainly someone else has had this exact problem\n",
    "  - almost certainly the solution is waiting for you\n",
    "- look for a stackoverflow answer with many up-votes\n",
    "  - ignore the green tick, this just means the person asking the question liked the answer\n",
    "  - typically an answer with many up-votes is a better option\n",
    "  - more recent answers can also be better: sometimes a library has changed since an older answer was written\n",
    "\n",
    "(For anyone who wasn't already doing this, that may be the most useful thing in this course)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51a0c7d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Display the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8adc78",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d21d31d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Column data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ba53f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5f136c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convert DateTimeOfCall to a date-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e050a60",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df[\"DateTimeOfCall\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bcb715",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# this looks like what we want..\n",
    "pd.to_datetime(df[\"DateTimeOfCall\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343266de",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# ..but which number is the month and which is the day?\n",
    "# how can we check if what we just did makes sense?\n",
    "pd.to_datetime(df[\"DateTimeOfCall\"]).plot()\n",
    "# should be a single monotonically increasing line: looks like days/months are mixed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab228e2e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# check the docs to see what options are available:\n",
    "?pd.to_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b75353",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# this looks better\n",
    "pd.to_datetime(df[\"DateTimeOfCall\"], dayfirst=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51a5988",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# consistency check: plot datetime vs index, should increase monotonically\n",
    "pd.to_datetime(df[\"DateTimeOfCall\"], dayfirst=True).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfecb82",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# replace DateTimeOfCall column in dataframe with this one\n",
    "df[\"DateTimeOfCall\"] = pd.to_datetime(df[\"DateTimeOfCall\"], dayfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7626329",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Use the datetime as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d983ca3c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.set_index(\"DateTimeOfCall\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8dbd1d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608f38cc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# can now use datetime to select rows: here is jan 2021\n",
    "df.loc[\"2021-01-01\":\"2021-01-31\", \"FinalDescription\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2146e773",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# can resample the timeseries: sum by month\n",
    "df.resample(\"M\")[\"IncidentNumber\"].count().plot(title=\"Monthly Calls\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ff1a9e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# or by day\n",
    "df.resample(\"d\")[\"IncidentNumber\"].count().plot(title=\"Daily Calls\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620bbbf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Missing data\n",
    "\n",
    "Different strategies for dealing with missing data:\n",
    "\n",
    "- Ignore the issue\n",
    "  - some things may break / not work as expected\n",
    "- Remove rows/columns with missing data\n",
    "  - remove all rows with missing data: `df.dropna(axis=0)`\n",
    "  - remove all columns with missing data: `df.dropna(axis=1)`\n",
    "- Guess (impute) missing data\n",
    "  - replace all missing entries with a value: `df.fillna(1)`\n",
    "  - replace missing entries with mean for that column `df.fillna(df.mean())`\n",
    "  - replace each missing entry with previous valid entry: `df.fillna(method=\"pad\")`\n",
    "  - replace missing by interpolating between valid entries: `df.interpolate()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b77f0a6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# count missing entries for each column\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b92e4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# If PumpCount is missing, typically so is PumpHoursTotal\n",
    "# 55 rows are missing at least one of these\n",
    "pump_missing = df[\"PumpCount\"].isna() | df[\"PumpHoursTotal\"].isna()\n",
    "print(pump_missing.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710987b5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# so we could choose to drop these rows\n",
    "df1 = df.drop(df.loc[pump_missing == True].index)\n",
    "# here we made a new dataset df1 with these rows dropped\n",
    "# to drop the rows from the original dataset df, could do:\n",
    "#\n",
    "# df = df.drop(df.loc[pump_missing == True].index)\n",
    "#\n",
    "# or:\n",
    "#\n",
    "# df.drop(df.loc[pump_missing == True].index, inplace=True)\n",
    "#\n",
    "print(len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85b5edc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# another equivalent way to do this\n",
    "df2 = df.dropna(subset=[\"PumpCount\", \"PumpHoursTotal\"])\n",
    "print(len(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b77336f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# but if we drop them, we lose valid data from other columns\n",
    "# let's look at the distribution of values:\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "df.plot.hist(y=\"PumpCount\", ax=axs[0])\n",
    "df.plot.hist(y=\"PumpHoursTotal\", ax=axs[1])\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e549308",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# looks like it would be better to replace missing PumpCount and PumpHoursTotal fields with 1\n",
    "?df.fillna\n",
    "df.fillna({\"PumpCount\": 1, \"PumpHoursTotal\": 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3f9bbe",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04033db2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Count the unique entries in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7357b4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.nunique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c1ad6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# this column is always the same:\n",
    "df[\"TypeOfIncident\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f53ea4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# so not interesting - we can drop it from our dataframe:\n",
    "df.drop(\"TypeOfIncident\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cc6edf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# \"cat\" and \"Cat\" are treated as different animals here:\n",
    "df[\"AnimalGroupParent\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a51479",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# select rows where AnimalGroupParent is \"cat\", replace with \"Cat\"\n",
    "df.loc[df[\"AnimalGroupParent\"] == \"cat\", \"AnimalGroupParent\"] = \"Cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa85510d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df[\"AnimalGroupParent\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9bfa1c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby(\"AnimalGroupParent\")[\"IncidentNumber\"].count().sort_values().plot.barh(\n",
    "    logx=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866db573",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SpecialServiceType\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c072632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apparently different hourly costs\n",
    "# does it depend on the type of event? or does it just increase over time?\n",
    "df[\"HourlyNotionalCost(£)\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6bc71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just goes up over time\n",
    "df[\"HourlyNotionalCost(£)\"].plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65c9fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"StnGroundName\")[\"IncidentNumber\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b1f238",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Plot location of calls on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f502b7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# drop missing longitude/latitude\n",
    "df2 = df.dropna(subset=[\"Longitude\", \"Latitude\"])\n",
    "# also drop zero values\n",
    "df2 = df2[df2[\"Latitude\"] != 0]\n",
    "# convert to geodataframe using geopandas\n",
    "import geopandas\n",
    "\n",
    "# set crs to EPSG:4326 to specify WGS84 Latitude/Longitude\n",
    "gdf = geopandas.GeoDataFrame(\n",
    "    df2,\n",
    "    geometry=geopandas.points_from_xy(df2[\"Longitude\"], df2[\"Latitude\"]),\n",
    "    crs=\"EPSG:4326\",\n",
    ")\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716cbfe9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import contextily as cx\n",
    "\n",
    "f, ax = plt.subplots(figsize=(16, 16))\n",
    "# plot location of calls involving animals\n",
    "gdf[gdf[\"AnimalGroupParent\"] == \"Cow\"].plot(\n",
    "    ax=ax, color=\"black\", alpha=0.3, label=\"Cow\"\n",
    ")\n",
    "gdf[gdf[\"AnimalGroupParent\"] == \"Deer\"].plot(\n",
    "    ax=ax, color=\"red\", alpha=0.3, label=\"Deer\"\n",
    ")\n",
    "gdf[gdf[\"AnimalGroupParent\"] == \"Fox\"].plot(ax=ax, color=\"blue\", alpha=0.3, label=\"Fox\")\n",
    "# add a basemap of the region using contextily\n",
    "cx.add_basemap(ax, crs=gdf.crs)\n",
    "plt.title(\"Call locations by animal\")\n",
    "plt.legend()\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73595505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
